{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Configured for local MIMIC database:\n",
      "\tuser = postgres\n",
      "\tdbname = mimic\n",
      "\thost = localhost\n",
      "\tschema_name = mimiciii\n",
      "\tquery_schema = SET search_path to mimiciii;\n",
      "\n",
      "Configured for my local MIMIC database (modified tables):\n",
      "\tmy_username = postgres\n",
      "\tmy_dbname = mimic\n",
      "\thost = localhost\n",
      "\tmy_schema_name = my_mimic_db\n",
      "\tmy_schema = SET search_path to my_mimic_db;\n"
     ]
    }
   ],
   "source": [
    "#configure for local mimic databse\n",
    "exec(open(\"../configs/configure_mimic.py\").read())\n",
    "exec(open(\"my_functions.py\").read())\n",
    "\n",
    "#Global vars\n",
    "CV=4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(35164, 294)\n",
      "35164\n",
      "1724\n",
      "(8792, 294)\n",
      "8792\n",
      "431\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "X_train = joblib.load(open(my_local_data_dir + 'X_train.joblib', 'rb'))\n",
    "y_train = joblib.load(open(my_local_data_dir + 'y_train.joblib', 'rb'))\n",
    "X_test = joblib.load(open(my_local_data_dir + 'X_test.joblib', 'rb'))\n",
    "y_test = joblib.load(open(my_local_data_dir + 'y_test.joblib', 'rb'))\n",
    "print(X_train.shape)\n",
    "print(len(y_train))\n",
    "print(np.sum(y_train))\n",
    "print(X_test.shape)\n",
    "print(len(y_test))\n",
    "print(np.sum(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Handle imballanced data using SMOTE\n",
    "(note decided not to use this, but keeping for demo purposes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# counter = Counter(y_train)\n",
    "# print(counter)\n",
    "# pct=round(counter[1]/len(y_train), 3)*100\n",
    "# print('starting positive rate = {}%'.format(pct))\n",
    "# oversample = SMOTE()\n",
    "# X_train_sm, y_train_sm = oversample.fit_resample(X_train, y_train)\n",
    "# counter = Counter(y_train_sm)\n",
    "# print(counter)\n",
    "# pct=round(counter[1]/len(y_train_sm), 3)*100\n",
    "# print('after SMOTE positive rate = {}%'.format(pct))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### set the SMOTE set as traning set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train = X_train_sm\n",
    "# y_train = y_train_sm\n",
    "# X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### train logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-478b388c6fd4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m#train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mlog_reg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m   1897\u001b[0m                       \u001b[0ml1_ratio\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0ml1_ratio\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1898\u001b[0m                       )\n\u001b[0;32m-> 1899\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miter_encoded_labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1900\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfolds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1901\u001b[0m             for l1_ratio in l1_ratios_)\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1015\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1016\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1017\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1018\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    907\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 909\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    910\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    560\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    561\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mLokyTimeoutError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#logistic regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "log_reg = LogisticRegressionCV(max_iter=1000,\n",
    "#                                solver='liblinear',\n",
    "                                 scoring='recall',\n",
    "                               n_jobs=4)\n",
    "\n",
    "#train\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### logistic regression cross validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#logistic regression cross validation\n",
    "probs_log_cv = cross_val_predict(log_reg, X_train, y_train, cv=CV, method=\"predict_proba\", n_jobs=3)\n",
    "scores_log_cv = probs_log_cv[:, 1]\n",
    "log_perf_cv = get_model_performance('logistic regression CV', X_train, scores_log_cv, y_train, pos_label=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#performance on the test set\n",
    "probs_test = log_reg.predict_proba(X_test)\n",
    "scores_test = probs_test[:, 1]\n",
    "test_perf = get_model_performance('logistic regression test set', X_test, scores_test, y_test, pos_label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------- OPTIMIZE RF\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "RAND_SEED = 123\n",
    "N_JOBS = 4\n",
    "# use RandomizedSearchCV() to optimized Random forest hyperparameters\n",
    "rf_clf = RandomForestClassifier(random_state=RAND_SEED,\n",
    "                                n_estimators=200)\n",
    "\n",
    "# choose parameter grid values\n",
    "max_depth = [42, 45, 47, 50]\n",
    "min_samples_split = [2]\n",
    "min_samples_leaf = [1]\n",
    "max_features = [\"auto\", \"sqrt\"]\n",
    "# max_samples = [int(X_train.shape[0]*0.25),\n",
    "#                int(X_train.shape[0]*0.5),\n",
    "#                int(X_train.shape[0]*0.75),\n",
    "#                int(X_train.shape[0])]\n",
    "\n",
    "# make grid dict\n",
    "random_grid = {'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'max_features': max_features}\n",
    "\n",
    "\n",
    "# ### run random search\n",
    "print('Random grid:')\n",
    "print(random_grid)\n",
    "rf_search = RandomizedSearchCV(estimator=rf_clf,\n",
    "                               param_distributions=random_grid,\n",
    "                               n_iter=100,\n",
    "                               scoring='recall',\n",
    "                               cv=4,\n",
    "                               verbose=2,\n",
    "                               random_state=RAND_SEED,\n",
    "                               n_jobs=N_JOBS)\n",
    "rf_search.fit(X_train, y_train)\n",
    "best_params = rf_search.best_params_\n",
    "print(rf_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = {'min_samples_split': 2,\n",
    "               'min_samples_leaf': 1,\n",
    "               'max_features': 'auto',\n",
    "               'max_depth': 45}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set up optimized rf model based on from best_params above\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "print(best_params)\n",
    "rf_opt = RandomForestClassifier(n_jobs=N_JOBS,\n",
    "                                n_estimators=1000,\n",
    "                                min_samples_split = best_params['min_samples_split'],\n",
    "                                min_samples_leaf = best_params['min_samples_leaf'],\n",
    "                                max_depth = best_params['max_depth'],\n",
    "                                bootstrap = True,\n",
    "                               random_state=RAND_SEED)\n",
    "\n",
    "#train\n",
    "rf_opt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#optimized model performance on training set\n",
    "scores_opt = rf_opt.predict_proba(X_train)[:, 1]\n",
    "opt_perf = get_model_performance('optimized random forest training', X_train, scores_opt, y_train, pos_label=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random forest cross validation performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#logistic regression cross validation\n",
    "rf_opt_cv = RandomForestClassifier(n_jobs=N_JOBS,\n",
    "                                n_estimators=1000,\n",
    "                                min_samples_split = best_params['min_samples_split'],\n",
    "                                min_samples_leaf = best_params['min_samples_leaf'],\n",
    "                                max_depth = best_params['max_depth'],\n",
    "                                bootstrap = True,\n",
    "                               random_state=RAND_SEED)\n",
    "probs_rf_cv = cross_val_predict(rf_opt_cv, X_train, y_train, cv=CV, method=\"predict_proba\", n_jobs=3)\n",
    "scores_rf_cv = probs_rf_cv[:, 1]\n",
    "rf_perf_cv = get_model_performance('random forest CV', X_train, scores_rf_cv, y_train, pos_label=1)\n",
    "print(rf_perf_cv['auc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.pipeline import make_pipeline\n",
    "pipe_lr = make_pipeline(RandomForestClassifier(n_estimators=500,\n",
    "                                               min_samples_split=best_params['min_samples_split'],\n",
    "                                               min_samples_leaf=best_params['min_samples_leaf'],\n",
    "                                               max_depth=best_params['max_depth'],\n",
    "                                               bootstrap=True,\n",
    "                                               random_state=RAND_SEED))\n",
    "train_sizes, train_scores, test_scores = learning_curve(estimator=pipe_lr,\n",
    "                                                        X=X_train,\n",
    "                                                        y=y_train,\n",
    "                                                        train_sizes=np.linspace(\n",
    "                                                            0.1, 1.0, 5),\n",
    "                                                        cv=CV,\n",
    "                                                        n_jobs=1,\n",
    "                                                       scoring = 'recall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot learning curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean = np.mean(train_scores, axis=1)\n",
    "train_std = np.std(train_scores, axis=1)\n",
    "test_mean = np.mean(test_scores, axis=1)\n",
    "test_std = np.std(test_scores, axis=1)\n",
    "\n",
    "plt.plot(train_sizes, train_mean, color='blue',\n",
    "         marker='o', markersize=5, label='Training F1')\n",
    "plt.fill_between(train_sizes, train_mean + train_std,\n",
    "                 train_mean - train_std, alpha=0.15, color='blue')\n",
    "plt.plot(train_sizes, test_mean, color='green', linestyle='--', marker='s',\n",
    "         markersize=5, label='Validation F1')\n",
    "plt.show()\n",
    "\n",
    "#\n",
    "plt.plot(train_sizes, test_mean, color='green', linestyle='--', marker='s',\n",
    "         markersize=5, label='Validation F1')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plot AUC from the two cross validations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mods = ['logistic regression',\n",
    "       'random forest']\n",
    "performance = [log_perf_cv['auc'],\n",
    "               rf_perf_cv['auc']]\n",
    "fig, ax = plt.subplots()\n",
    "y_pos = np.arange(len(mods))\n",
    "ax.barh(y_pos, performance, align='center', color='grey')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(mods)\n",
    "ax.invert_yaxis()  # labels read top-to-bottom\n",
    "ax.set_xlabel('AUC')\n",
    "plt.show()\n",
    "auc_df = pd.DataFrame({'model':mods, 'auc':performance})\n",
    "auc_df.to_csv('../data/for_plotting/auc_comparison.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### performance on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#predict for test set\n",
    "exec(open(\"my_functions.py\").read())\n",
    "test_scores = rf_opt.predict_proba(X_test)[:, 1]\n",
    "test_perf = get_model_performance('optimized random forest TEST', X_test, test_scores, y_test, pos_label=1)\n",
    "\n",
    "\n",
    "threshold = 0.3\n",
    "opt_pred = (test_scores > threshold).astype('int')\n",
    "y_num = (y_test==1).astype('int')\n",
    "print('Confusion matrix for threshold = {}:'.format(round(threshold, 2)))\n",
    "cm = confusion_matrix(y_num, opt_pred)\n",
    "print(cm)\n",
    "print('Classification report:')\n",
    "print(classification_report(y_num, opt_pred))\n",
    "joblib.dump(test_perf, '../data/for_app/performance.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perf_out = pd.DataFrame({'fpr':test_perf['fpr'],\n",
    "                       'tpr': test_perf['tpr'],\n",
    "                       'auc' : test_perf['auc']})\n",
    "perf_out.to_csv('../data/for_plotting/auc_curve.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "importances = rf_opt.feature_importances_\n",
    "std = np.std([tree.feature_importances_ for tree in rf_opt.estimators_],\n",
    "             axis=0)\n",
    "indices = np.argsort(importances)[::-1]\n",
    "features = X_test.columns[indices]\n",
    "idat = pd.DataFrame({'feature':features,\n",
    "                     'importance': importances,\n",
    "                   'std': std,\n",
    "                   'index':indices})\n",
    "idat = idat.sort_values('importance', ascending=False)\n",
    "print(idat.shape)\n",
    "idat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### add back in the human readable names for features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### diagnoses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload the diagnoses table with full names for diagnosis variables\n",
    "query = query_schema + \\\n",
    "    \"\"\"select \n",
    "    *\n",
    "    from D_ICD_DIAGNOSES\"\"\"\n",
    "ddat = pd.read_sql_query(query, con)\n",
    "ddat['feature'] = ['diagnosis_icd9_' + x for x in ddat['icd9_code']]\n",
    "\n",
    "# merge the importance data with diagnoses table\n",
    "idat_out = pd.merge(idat, ddat, how='left', on='feature')\n",
    "to_change = idat_out['short_title'].notna()\n",
    "idat_out.loc[to_change, 'feature'] = \\\n",
    "    'diagnosis: ' + idat_out['short_title']\n",
    "idat_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# upload the procedure table with full names for procedures\n",
    "query = query_schema + \\\n",
    "    \"\"\"select \n",
    "    *\n",
    "    from D_ICD_PROCEDURES\"\"\"\n",
    "ddat = pd.read_sql_query(query, con)\n",
    "ddat['feature'] = ['procedure_icd9_' + x for x in ddat['icd9_code']]\n",
    "\n",
    "# merge the importance data with diagnoses table\n",
    "idat_out = idat_out.loc[:, idat.columns]\n",
    "idat_out = pd.merge(idat_out, ddat, how='left', on='feature')\n",
    "to_change = (idat_out['short_title'].notna())\n",
    "idat_out.loc[to_change, 'feature'] = \\\n",
    "    'procedure: ' + idat_out['short_title']\n",
    "idat_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### change prefixes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>std</th>\n",
       "      <th>index</th>\n",
       "      <th>row_id</th>\n",
       "      <th>icd9_code</th>\n",
       "      <th>short_title</th>\n",
       "      <th>long_title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>age</td>\n",
       "      <td>0.030430</td>\n",
       "      <td>0.005025</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>icu_duration</td>\n",
       "      <td>0.028062</td>\n",
       "      <td>0.004997</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drug: Phenylephrine</td>\n",
       "      <td>0.023563</td>\n",
       "      <td>0.004285</td>\n",
       "      <td>201</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drug: Metoprolol Tartrate</td>\n",
       "      <td>0.021439</td>\n",
       "      <td>0.003942</td>\n",
       "      <td>182</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>drug: Oxycodone-Acetaminophen</td>\n",
       "      <td>0.015156</td>\n",
       "      <td>0.003181</td>\n",
       "      <td>198</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>drug: Albuterol 0.083% Neb Soln</td>\n",
       "      <td>0.001468</td>\n",
       "      <td>0.001163</td>\n",
       "      <td>114</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>290</th>\n",
       "      <td>drug: Potassium Chloride</td>\n",
       "      <td>0.001467</td>\n",
       "      <td>0.000994</td>\n",
       "      <td>207</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>diagnosis: Crnry athrscl natve vssl</td>\n",
       "      <td>0.001384</td>\n",
       "      <td>0.000993</td>\n",
       "      <td>42</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>DNword_warfarin</td>\n",
       "      <td>0.001237</td>\n",
       "      <td>0.000959</td>\n",
       "      <td>272</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>293</th>\n",
       "      <td>drug: Fentanyl Citrate</td>\n",
       "      <td>0.001186</td>\n",
       "      <td>0.000962</td>\n",
       "      <td>145</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>294 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 feature  importance       std  index  row_id  \\\n",
       "0                                    age    0.030430  0.005025      0     NaN   \n",
       "1                           icu_duration    0.028062  0.004997      1     NaN   \n",
       "2                    drug: Phenylephrine    0.023563  0.004285    201     NaN   \n",
       "3              drug: Metoprolol Tartrate    0.021439  0.003942    182     NaN   \n",
       "4          drug: Oxycodone-Acetaminophen    0.015156  0.003181    198     NaN   \n",
       "..                                   ...         ...       ...    ...     ...   \n",
       "289      drug: Albuterol 0.083% Neb Soln    0.001468  0.001163    114     NaN   \n",
       "290             drug: Potassium Chloride    0.001467  0.000994    207     NaN   \n",
       "291  diagnosis: Crnry athrscl natve vssl    0.001384  0.000993     42     NaN   \n",
       "292                      DNword_warfarin    0.001237  0.000959    272     NaN   \n",
       "293               drug: Fentanyl Citrate    0.001186  0.000962    145     NaN   \n",
       "\n",
       "    icd9_code short_title long_title  \n",
       "0         NaN         NaN        NaN  \n",
       "1         NaN         NaN        NaN  \n",
       "2         NaN         NaN        NaN  \n",
       "3         NaN         NaN        NaN  \n",
       "4         NaN         NaN        NaN  \n",
       "..        ...         ...        ...  \n",
       "289       NaN         NaN        NaN  \n",
       "290       NaN         NaN        NaN  \n",
       "291       NaN         NaN        NaN  \n",
       "292       NaN         NaN        NaN  \n",
       "293       NaN         NaN        NaN  \n",
       "\n",
       "[294 rows x 8 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drug prefix from drug_ to drug: \n",
    "to_change = idat_out['feature'].str.startswith('drug_')\n",
    "idat_out['feature'] = idat_out['feature'].str.replace('drug_', 'drug: ')\n",
    "idat_out\n",
    "\n",
    "#religion prefix from religion_ to religion: \n",
    "to_change = idat_out['feature'].str.startswith('drug_')\n",
    "idat_out['feature'] = idat_out['feature'].str.replace('religion_', 'religion: ')\n",
    "idat_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save for app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "joblib.dump(idat_out.loc[idat_out['importance']>0.0,:], '../data/for_app/importances.joblib');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
